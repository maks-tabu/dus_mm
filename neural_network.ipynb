{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22278,
     "status": "ok",
     "timestamp": 1622698525801,
     "user": {
      "displayName": "Maxim Tabolin",
      "photoUrl": "",
      "userId": "11591994697218843812"
     },
     "user_tz": -180
    },
    "id": "57333554",
    "outputId": "10e92f34-6eac-4e2a-c221-71f4e86f8c06"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#os.chdir('/content/drive/MyDrive/Github/dus_mm/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import glob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "os.chdir('data')\n",
    "\n",
    "columnsX = ['freq','AX','BX','BY','CY','CX','DX','DY','AY']\n",
    "columnsY = ['AX','BX','BY','CY','CX','DX','DY','AY','AQ','AL','BQ','BL','CQ','CL','DQ','DL']\n",
    "columnsYout = ['AQ','AL','BQ','BL','CQ','CL','DQ','DL','X','Y','Q','L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3644,
     "status": "ok",
     "timestamp": 1622699009319,
     "user": {
      "displayName": "Maxim Tabolin",
      "photoUrl": "",
      "userId": "11591994697218843812"
     },
     "user_tz": -180
    },
    "id": "C_KWQPtQZY-L"
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame()\n",
    "y = pd.DataFrame()\n",
    "numb_files = len(glob.glob('data_output*'))\n",
    "for i in glob.glob('data_output*'): \n",
    "    numb = i[11]\n",
    "    if (numb == 'data_output.txt'):\n",
    "        numb = ''\n",
    "    y = pd.concat([y,pd.read_table(os.path.join('data_output%s.txt' % numb), header = 0, names = columnsY, \n",
    "                                   index_col = False, sep='\\s+', engine='python', dtype ='float')], ignore_index = 1)\n",
    "    X = pd.concat([X,pd.read_table(os.path.join('data_input%s.txt' % numb), header = 0, names = columnsX, \n",
    "                                   index_col = False, sep='\\s+', engine='python', dtype =\"float\")], ignore_index = 1)\n",
    "X = X.loc[:20*4+3]\n",
    "y = y.loc[:20]\n",
    "X = utils.init_in(X)\n",
    "y = utils.decomposition(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1622709178308,
     "user": {
      "displayName": "Maxim Tabolin",
      "photoUrl": "",
      "userId": "11591994697218843812"
     },
     "user_tz": -180
    },
    "id": "7GvxIsNBZyow"
   },
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, neurons: int = 256, activation: str = 'linear'):\n",
    "        self.neurons = neurons\n",
    "        self.activation = activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1622711402216,
     "user": {
      "displayName": "Maxim Tabolin",
      "photoUrl": "",
      "userId": "11591994697218843812"
     },
     "user_tz": -180
    },
    "id": "pEAJnCW6asSZ"
   },
   "outputs": [],
   "source": [
    "class NN_model():\n",
    "  \n",
    "    def __init__(self, input_dimension: int):\n",
    "        self.sequential = [Layer(input_dimension)]\n",
    "        self.theta = np.array([])\n",
    "        self.loss = 'mean_squared_error'\n",
    "        self.optimizer = 'adam'\n",
    "        self.num_iterations = 10\n",
    "        self.beta_1 = 0.9\n",
    "        self.beta_2 = 0.9\n",
    "        self.step_size = 0.1\n",
    "\n",
    "    def add(self, layer: Layer):\n",
    "        self.sequential.append(layer)\n",
    "        self.initial_theta()\n",
    "\n",
    "    def initial_theta(self):\n",
    "        layer_in = self.sequential[-2]\n",
    "        layer_out = self.sequential[-1]\n",
    "        epsilon = np.sqrt(6)/np.sqrt(layer_in.neurons + layer_out.neurons)\n",
    "        init_theta = np.random.rand(layer_out.neurons,layer_in.neurons + 1)*2*epsilon - epsilon\n",
    "        self.theta = np.hstack([self.theta, init_theta.reshape(init_theta.size)])\n",
    "\n",
    "    def activation(self, layer: Layer, x, diff: bool = False):\n",
    "        if (layer.activation == 'relu'):\n",
    "            if (diff == True):\n",
    "                x[x >= 0] = 1\n",
    "                x[x < 0] = 0\n",
    "            else:\n",
    "                x[x < 0] = 0\n",
    "        elif (layer.activation == 'linear'):\n",
    "            pass\n",
    "        return x\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        a = x\n",
    "        a_out = np.array(a.reshape([a.size]))\n",
    "        bias1 = 0\n",
    "        for i in range(1,len(self.sequential)):\n",
    "            layer1 = self.sequential[i-1]\n",
    "            layer2 = self.sequential[i]\n",
    "            bias2 = bias1 + (layer1.neurons + 1) * layer2.neurons\n",
    "            theta12 = self.theta[bias1:bias2].reshape(layer2.neurons, layer1.neurons+1)\n",
    "            z = np.dot(np.concatenate((np.ones([a.shape[0],1]),a),axis = 1), theta12.T)\n",
    "            a = self.activation(layer2, z)\n",
    "            a_out = np.hstack([a_out, a.reshape(a.size)])\n",
    "            bias1 = bias2\n",
    "        return a_out\n",
    "\n",
    "    def backprop(self, a_out, y): \n",
    "        grad_out = np.array([])\n",
    "        bias_theta1 = 0\n",
    "        bias_a1 = 0\n",
    "        for i in range(1,len(self.sequential)):\n",
    "            layer1 = self.sequential[-(i+1)]\n",
    "            layer2 = self.sequential[-i]\n",
    "            bias_theta2 = bias_theta1 + (layer1.neurons + 1) * layer2.neurons\n",
    "            bias_a2 = bias_a1 + layer1.neurons * y.shape[0]\n",
    "            bias_a3 = bias_a2 + layer2.neurons * y.shape[0]\n",
    "            a1 = a_out[-bias_a2:-bias_a1].reshape((y.shape[0], layer1.neurons))\n",
    "            a1 = np.concatenate((np.ones([a1.shape[0],1]), a1),axis = 1)\n",
    "            a2 = a_out[-bias_a3:-bias_a2].reshape((y.shape[0], layer2.neurons))\n",
    "            if (i == 1):\n",
    "                delta = self.compute_delta_end(a2, y)\n",
    "            else:\n",
    "                delta = np.dot(delta,theta12[:,1:]) *  self.activation(layer2, a2)\n",
    "            grad = (1/y.shape[0]) * (np.dot(delta.T, a1))\n",
    "            grad_out = np.hstack([grad.reshape(grad.size), grad_out])\n",
    "            theta12 = self.theta[-bias_theta2:bias_theta1].reshape(layer2.neurons, layer1.neurons+1)\n",
    "            bias_theta1 = bias_theta2\n",
    "            bias_a1 = bias_a2\n",
    "        return grad_out\n",
    "\n",
    "    def compute_delta_end(self,a_end,y):\n",
    "        if (self.loss == 'mean_squared_error'):\n",
    "            delta = (a_end - y)\n",
    "        return delta \n",
    "    #def compute_loss(self, a_out):\n",
    "\n",
    "    def optimize(self, x, y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        m = np.zeros(self.theta.shape)\n",
    "        v = np.zeros(self.theta.shape)\n",
    "        if (self.optimizer == 'adam'):\n",
    "            for t in range(self.num_iterations):\n",
    "                a_out = self.feedforward(x)\n",
    "                grad = self.backprop(a_out,y)\n",
    "                m = self.beta_1 * m + (1 - self.beta_1) * grad\n",
    "                v = beta_2 * v + (1 - self.beta_2) * np.power(grad, 2)\n",
    "                m_hat = m / (1 - np.power(self.beta_1, t))\n",
    "                v_hat = v / (1 - np.power(self.beta_2, t))\n",
    "                self.theta = self.theta - self.step_size * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(len(self.sequential))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622711403386,
     "user": {
      "displayName": "Maxim Tabolin",
      "photoUrl": "",
      "userId": "11591994697218843812"
     },
     "user_tz": -180
    },
    "id": "6Sw-LVFnbkr0"
   },
   "outputs": [],
   "source": [
    "dus_mm = NN_model(X.shape[1])\n",
    "dus_mm.add(Layer(64, 'relu'))\n",
    "dus_mm.add(Layer(64, 'relu'))\n",
    "dus_mm.add(Layer(64, 'relu'))\n",
    "dus_mm.add(Layer(y.shape[1], 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1622711403772,
     "user": {
      "displayName": "Maxim Tabolin",
      "photoUrl": "",
      "userId": "11591994697218843812"
     },
     "user_tz": -180
    },
    "id": "bzbjiq-2AB7M",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (21,64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-755d6fd05fc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdus_mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdus_mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-115-65f90cea8dec>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, a_out, y)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mbias_a2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbias_a1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneurons\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mbias_a3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbias_a2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneurons\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbias_a2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbias_a1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbias_a3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbias_a2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (21,64)"
     ]
    }
   ],
   "source": [
    "a_out = dus_mm.feedforward(np.array(X))\n",
    "dus_mm.backprop(a_out,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhLXVVzt2jYO"
   },
   "outputs": [],
   "source": [
    "X1 = X\n",
    "X1 = np.concatenate((np.ones([X1.shape[0],1]),X1),axis = 1)\n",
    "X2 = relu(np.dot(X1,theta1.T))\n",
    "X2 = np.concatenate((np.ones([X2.shape[0],1]),X2),axis = 1)\n",
    "X3 = relu(np.dot(X2,theta2.T))\n",
    "X3 = np.concatenate((np.ones([X3.shape[0],1]),X3),axis = 1)\n",
    "X4 = linear(np.dot(X3,theta3.T))\n",
    "\n",
    "delta4 = (X4 - y)\n",
    "delta3 = np.dot(delta4,theta3[:,1:]) * relu(X3[:,1:],True)\n",
    "delta2 = np.dot(delta3,theta2[:,1:]) * relu(X2[:,1:],True)\n",
    "grad1 =  (1/n)*(np.dot(delta2.T,X1))\n",
    "grad2 =  (1/n)*(np.dot(delta3.T,X2))\n",
    "grad3 =  (1/n)*(np.dot(delta4.T,X3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFNOGziq2viV"
   },
   "outputs": [],
   "source": [
    "for t in range(num_iterations):\n",
    "    grad = compute_gradient(x, y)\n",
    "    m = beta_1 * m + (1 - beta_1) * grad\n",
    "    v = beta_2 * v + (1 - beta_2) * np.power(grad, 2)\n",
    "    m_hat = m / (1 - np.power(beta_1, t))\n",
    "    v_hat = v / (1 - np.power(beta_2, t))\n",
    "    w = w - step_size * m_hat / (np.sqrt(v_hat) + epsilon)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "neural_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
